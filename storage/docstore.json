{"docstore/metadata": {"d73b33d0-b3b2-4b38-b850-64cd7e05c342": {"doc_hash": "3093c45b3a894f350bee7e8e0680cf7b8c26ed264588450486c4f7f8a7be9ccd"}, "302b4cd0-5ce1-468b-9e5e-00b5dec5b011": {"doc_hash": "630e0bfb6f24a707d40c2de4c7e15becd163a6ae3198b33a305badd25a4be4e4"}, "909d2f5b-7e17-4657-95af-97b264873214": {"doc_hash": "ba7edd05ee4f58460439fb1bd0d3989bb27e2bf4bbaf87ce86c4fb6c70ed1efa"}, "1ea323fb-d256-453a-8c8c-2bfd9ef7ef07": {"doc_hash": "bc0c2a96011f81b587976f14386c2988e38ee037595eaaec2e64ad89d6ee418d"}, "2ebc0465-d661-43c9-80a1-c6df4100cd2f": {"doc_hash": "b5c02356c24bcc118331dcd66983973b9a7c9b9561b26c44e5695ace78a417fd"}, "ec7b4db9-f8b8-4cab-8d5c-396c48a2738f": {"doc_hash": "b6541810263eb7245450259506b42f55be220eac21845f0fd2126293731f320a"}, "13bb916b-9ea6-4b23-a10b-fbeecd0e544b": {"doc_hash": "e546f75588ab2a6ace3f153422c79afa96798e77575dc39ebfdafd87d805677d"}, "b5fa37a6-cd7c-4113-9e2c-2cdf8c86f8c6": {"doc_hash": "82196704fd7b2ff9409cf28772d863f90353ae596a9da8d08a79000908572791"}, "2fbd7d4e-bed3-400f-b11c-83e1655c8690": {"doc_hash": "3093c45b3a894f350bee7e8e0680cf7b8c26ed264588450486c4f7f8a7be9ccd", "ref_doc_id": "d73b33d0-b3b2-4b38-b850-64cd7e05c342"}, "335fc737-6548-4460-bef4-024cd5e0fa43": {"doc_hash": "630e0bfb6f24a707d40c2de4c7e15becd163a6ae3198b33a305badd25a4be4e4", "ref_doc_id": "302b4cd0-5ce1-468b-9e5e-00b5dec5b011"}, "45d0ada2-5336-4379-9bd3-061fdfb48be5": {"doc_hash": "ba7edd05ee4f58460439fb1bd0d3989bb27e2bf4bbaf87ce86c4fb6c70ed1efa", "ref_doc_id": "909d2f5b-7e17-4657-95af-97b264873214"}, "92898709-fb7a-4d25-8019-b145fab5a093": {"doc_hash": "bbd368b3f24c469850bd5ca9d75fe2138db94d04e969c1893beaa30b32650675", "ref_doc_id": "1ea323fb-d256-453a-8c8c-2bfd9ef7ef07"}, "3de1a0f7-bb8e-4a41-bdc2-27645f192a17": {"doc_hash": "bbf04b48e5b0873e4f66209a93899f9d14970837cdbb84abddef141c31eff83f", "ref_doc_id": "1ea323fb-d256-453a-8c8c-2bfd9ef7ef07"}, "bf84070f-da7b-405b-b045-711b7a3afc1c": {"doc_hash": "b5c02356c24bcc118331dcd66983973b9a7c9b9561b26c44e5695ace78a417fd", "ref_doc_id": "2ebc0465-d661-43c9-80a1-c6df4100cd2f"}, "bcc175c8-b731-440c-9737-de8224a15aa4": {"doc_hash": "b6541810263eb7245450259506b42f55be220eac21845f0fd2126293731f320a", "ref_doc_id": "ec7b4db9-f8b8-4cab-8d5c-396c48a2738f"}, "2244e4b0-72f3-4cd2-bbfc-f52a08a52783": {"doc_hash": "e546f75588ab2a6ace3f153422c79afa96798e77575dc39ebfdafd87d805677d", "ref_doc_id": "13bb916b-9ea6-4b23-a10b-fbeecd0e544b"}, "76358c52-9704-4d91-90b3-c3e7725d48b8": {"doc_hash": "82196704fd7b2ff9409cf28772d863f90353ae596a9da8d08a79000908572791", "ref_doc_id": "b5fa37a6-cd7c-4113-9e2c-2cdf8c86f8c6"}}, "docstore/data": {"2fbd7d4e-bed3-400f-b11c-83e1655c8690": {"__data__": {"id_": "2fbd7d4e-bed3-400f-b11c-83e1655c8690", "embedding": null, "metadata": {"page_label": "1", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d73b33d0-b3b2-4b38-b850-64cd7e05c342", "node_type": "4", "metadata": {"page_label": "1", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "hash": "3093c45b3a894f350bee7e8e0680cf7b8c26ed264588450486c4f7f8a7be9ccd", "class_name": "RelatedNodeInfo"}}, "text": "AUTOGENSTUDIO : A No-Code Developer Tool for Building and\nDebugging Multi-Agent Systems\nVictor Dibia, Jingya Chen, Gagan Bansal, Suff Syed,\nAdam Fourney, Erkang Zhu, Chi Wang, Saleema Amershi\nMicrosoft Research, Redmond, United States\n{victordibia, jingyachen, gaganbansal, suffsyed, adam.fourney,\nerkang.zhu, chiw, samershi}@microsoft.com\nAbstract\nMulti-agent systems, where multiple agents\n(generative AI models + tools) collaborate, are\nemerging as an effective pattern for solving\nlong-running, complex tasks in numerous do-\nmains. However, specifying their parameters\n(such as models, tools, and orchestration mech-\nanisms etc,.) and debugging them remains chal-\nlenging for most developers. To address this\nchallenge, we present AUTOGENSTUDIO , a\nno-code developer tool for rapidly prototyping,\ndebugging, and evaluating multi-agent work-\nflows built upon the AUTOGENframework.\nAUTOGENSTUDIO offers a web interface and\na Python API for representing LLM-enabled\nagents using a declarative (JSON-based) speci-\nfication. It provides an intuitive drag-and-drop\nUI for agent workflow specification, interactive\nevaluation and debugging of workflows, and\na gallery of reusable agent components. We\nhighlight four design principles for no-code\nmulti-agent developer tools and contribute an\nopen-source implementation.1\n1 Introduction\nWhen combined with the ability to act (e.g., using\ntools), Generative AI models function as agents, en-\nabling complex problem-solving capabilities. Im-\nportantly, recent research has shown that transi-\ntioning from prescribed (fixed) agent pipelines to a\nmulti-agent setup with autonomous capabilities can\nresult in desirable behaviors such as improved fac-\ntuality and reasoning (Du et al., 2023), as well as\ndivergent thinking (Liang et al., 2023). These obser-\nvations have driven the development of application\nframeworks such as AutoGen (Wu et al., 2023),\nCAMEL (Li et al., 2024), and TaskWeaver (Qiao\net al., 2023), which simplify the process of crafting\nmulti-agent applications expressed as Python code.\nHowever, while multi-agent applications advance\n1https://github.com/microsoft/autogen/tree/\nautogenstudio/samples/apps/autogen-studio\nInitiat or\nCode ex ecut orR epresent user, execute co..Userpr o xyPlan and generate book content including text and images.Book generation gr oup chat manager\nDrag & dr op t o add a skillGenerate content for each...Cont ent Agent\nGPT 4 T urboGenerate imagesImage Agent\nGPT 4 T urbo\nImage generat or\nDrag to add a skillV erify the content meet par...Q A Agent\nDrag to add a model\nAgent AAgent BFigure 1: AUTOGENSTUDIO provides a drag-n-drop\nUI where models, skills/tools, memory components can\nbe defined, attached to agents and agents attached to\nworkflows.\nour capacity to solve complex problems, they also\nintroduce new challenges. For example, developers\nmust now configure a large number of parameters\nfor these systems including defining agents (e.g.,\nthe model to use, prompts, tools or skills available\nto the agent, number of action steps an agent can\ntake, task termination conditions etc.), communica-\ntion and orchestration mechanisms - i.e., the order\nor sequence in which agents act as they collabo-\nrate on a task. Additionally, developers need to\ndebug and make sense of complex agent interac-\ntions to extract signals for system improvement.\nAll of these factors can create significant barriers\nto entry and make the multi-agent design process\ntedious and error-prone. To address these chal-\nlenges, we have developed AUTOGENSTUDIO , a\ntool for rapidly prototyping, debugging, and evalu-\nating MULTI -AGENT workflows. Our contributions\nare highlighted as follows:\n\u2022AUTOGENSTUDIO - a developer-focused tool\n(UI and backend Web and Python API) for\ndeclaratively specifying and debugging (human-\nin-the-loop and non-interactive) MULTI -AGENT\nworkflows. AUTOGENSTUDIO provides a novelarXiv:2408.15247v1  [cs.SE]  9 Aug 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3915, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "335fc737-6548-4460-bef4-024cd5e0fa43": {"__data__": {"id_": "335fc737-6548-4460-bef4-024cd5e0fa43", "embedding": null, "metadata": {"page_label": "2", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "302b4cd0-5ce1-468b-9e5e-00b5dec5b011", "node_type": "4", "metadata": {"page_label": "2", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "hash": "630e0bfb6f24a707d40c2de4c7e15becd163a6ae3198b33a305badd25a4be4e4", "class_name": "RelatedNodeInfo"}}, "text": "drag-and-drop experience (Figure 1) for rapidly\nauthoring complex MULTI -AGENT agent work-\nflows, tools for profiling/debugging agent ses-\nsions, and a gallery of reusable/shareable MULTI -\nAGENT components.\n\u2022We introduce profiling capabilities with visual-\nizations of messages/actions by agents and met-\nrics (costs, tool invocations, and tool output sta-\ntus) for debugging MULTI -AGENT workflows.\n\u2022Based on our experience building and supporting\nAUTOGENSTUDIO as an open-source tool with\na significant user base (over 200 Kdownloads\nwithin a 5-month period), we outline emerg-\ning design patterns for MULTI -AGENT developer\ntooling and future research directions.\nTo the best of our knowledge, AUTOGENSTU-\nDIO is the first open-source project to explore a\nno-code interface for autonomous MULTI -AGENT\napplication development, providing a suitable plat-\nform for research and practice in MULTI -AGENT\ndeveloper tooling.\n2 Related Work\n2.1 Agents ( LLM s + Tools)\nGenerative AI models face limitations, including\nhallucination \u2014 generating content not grounded\nin fact \u2014 and limited performance on reasoning\ntasks or novel out-of-distribution problems. To\naddress these issues, practice has shifted towards\nagentic implementations where models are given\naccess to tools to act and augment their perfor-\nmance (Mialon et al., 2023). Agentic implemen-\ntations, such as React (Yao et al., 2022), explore\na Reason and Act paradigm that uses LLMs to\ngenerate both reasoning traces and task-specific\nactions in an interleaved manner. As part of this\nprocess, developers have explored frameworks that\nbuild prescriptive pipelines interleaving models and\ntools (e.g., LIDA (Dibia, 2023), LangChain (Chase,\n2022)). However, as tasks become more complex,\nrequiring lengthy context and the ability to inde-\npendently adapt to dynamic problem spaces, pre-\ndefined pipelines demonstrate limited performance\n(Liu et al., 2024). This limitation has led to the\nexploration of more flexible and adaptive agent\narchitectures.\n2.2 MULTI -AGENT Frameworks\nSeveral frameworks have been proposed to provide\nabstractions for creating such applications. Au-toGen (Wu et al., 2023) is an open-source exten-\nsible framework that allows developers to build\nlarge MULTI -AGENT applications. CAMEL (Li\net al., 2024) is designed to facilitate autonomous\ncooperation among communicative agents through\nrole-playing, using inception prompting to guide\nchat agents toward task completion while align-\ning with human intentions. OS-Copilot (Wu et al.,\n2024) introduces a framework for building general-\nist agents capable of interfacing with comprehen-\nsive elements in an operating system, including the\nweb, code terminals, files, multimedia, and various\nthird-party applications. It explores the use of a\ndedicated planner module, a configurator, and an\nexecutor, as well as the concept of tools ( Python\nfunctions or calls to API endpoints) or skills (tools\nthat can be learned and reused on the fly).\nMulti-Agent Core Concepts\n1.Model : Generative AI model used to\ndrive core agent behaviors.\n2.Skills/Tools : Code or APIs used to ad-\ndress specific tasks.\n3.Memory : Short term (e.g., lists) or long\nterm (vector databases) used for to save\nand recall information.\n4.Agent : A configuration that ties together\nthe model, skills, memory components\nand behaviors.\n5.Workflow : A configuration of a set of\nagents and how they interact to address\ntasks (e.g., order or sequence in which\nagents act, task planning, termination\nconditions etc.).\nCollectively, these tools support a set of core\ncapabilities - definition of agent parameters - such\nas generative AI models ,skills / tools or memory,\nand agent workflows - specifications of how these\nagents can collaborate. However, most of these\nframeworks primarily support a code-first represen-\ntation of agent workflows, which presents a high\nbarrier to entry and rapid prototyping. They also\ndo not provide tools or metrics for agent debugging\nand evaluation. Additionally, they lack structured\nreusable templates to bootstrap or accelerate the\nagent workflow creation process. AUTOGENSTU-", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4112, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "45d0ada2-5336-4379-9bd3-061fdfb48be5": {"__data__": {"id_": "45d0ada2-5336-4379-9bd3-061fdfb48be5", "embedding": null, "metadata": {"page_label": "3", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "909d2f5b-7e17-4657-95af-97b264873214", "node_type": "4", "metadata": {"page_label": "3", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "hash": "ba7edd05ee4f58460439fb1bd0d3989bb27e2bf4bbaf87ce86c4fb6c70ed1efa", "class_name": "RelatedNodeInfo"}}, "text": "DIOaddresses these limitations by providing a vi-\nsual interface to declaratively define and visualize\nagent workflows, test and evaluate these workflows,\nand offer templates for common MULTI -AGENT\ntasks to streamline development. While this work\nis built on the AUTOGENopen source library (Wu\net al., 2023) and inherits the core abstractions for\nrepresenting agents, the proposed design patterns\non no-code developer tools are intended to apply\nto all MULTI -AGENT frameworks.\n3 Design Goals\nAUTOGENSTUDIO is designed to enhance the\nMULTI -AGENT developer experience by focusing\non three core objectives:\nRapid Prototyping: Provide a playground where\ndevelopers can quickly specify agent configura-\ntions and compose these agents into effective multi-\nagent workflows.\nDeveloper Tooling: Offer tools designed to help\ndevelopers understand and debug agent behaviors,\nfacilitating the improvement of multi-agent sys-\ntems.\nReusable Templates: Present a gallery of reusable,\nshareable templates to bootstrap agent workflow\ncreation. This approach aims to establish shared\nstandards and best practices for MULTI -AGENT sys-\ntem development, promoting wider adoption and\nimplementation of MULTI -AGENT solutions.\n4 System Design\nAUTOGENSTUDIO is implemented across two\nhigh-level components: a frontend user interface\n(UI) and a backend API (web, python and com-\nmand line). It can be installed via the PyPI package\nmanager (listing 1).\npip install autogenstudio\nautogenstudio ui --port 8081\nlisting 1: AUTOGENSTUDIO can be installed from\nPyPI (pip) and the UI launched from the command line.\n4.1 User Interface\nThe frontend web interface in AUTOGENSTU-\nDIO is built using React and implements three\nmain views that support several key functionalities.\nThebuild view enables users to author (define-and-\ncompose) multi-agent workflows. The playgroundview allows for interactive task execution and work-\nflow debugging, with options to export and deploy.\nThegallery view facilitates the reuse and sharing\nof agent artifact templates.\n4.1.1 Building Workflows\nThe build view in the UI (see Figure 1) offers a\ndefine-and-compose experience, allowing develop-\ners to declaratively define low-level components\nand iteratively compose them into a workflow. For\ninstance, users can define configurations for mod-\nels, skills/tools (represented as Python functions\naddressing specific tasks), or memory stores (e.g.,\ndocuments organized in a vector database). Each\nentity is saved in a database for use across inter-\nface interactions. Subsequently, they can define\nan agent, attaching models, skills, and memory to\nit. Several agent default templates are provided\nfollowing AUTOGENabstractions - a UserProxy\nagent (has a code execution tool by default), an\nAssistantAgent (has a generative AI model default),\nand a GroupChat agent (an abstraction container\nfor defining a list of agents, and how they interact).\nFinally, workflows can be defined, with existing\nagents attached to these workflows. The default\nworkflow patterns supported are autonomous chat\n(agents exchange messages and actions across con-\nversation turns until a termination condition is met)\nand sequential chat (a sequence of agents defined,\neach agent processes its input in order and passes\non a summary of their output to the next agent).\nThe workflow composition process is further en-\nhanced by supporting a drag-and-drop interaction\ne.g., skills/models can be dragged to agents and\nagents into workflows.\n4.1.2 Testing and Debugging Workflows\nWorkflows can be tested in-situ in the build view,\nor more systematically explored within the play-\nground view. The playground view allows users\ncreate sessions , attach workflows to the session,\nand run tasks (single shot or multi-turn). Sessions\ncan be shared (to illustrate workflow performance)\nand multiple sessions can be compared. AUTOGEN\nSTUDIO provides two features to support debug-\nging. First, it provides an observe view where as\ntasks progress, messages and actions performed by\nagents are streamed to the interface, and all gen-\nerated artifacts are displayed (e.g., files such as\nimages, code, documents etc). Second a post-hoc\nprofiler view is provided where a set of metrics are\nvisualized for each task addressed by a workflow -", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4257, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "92898709-fb7a-4d25-8019-b145fab5a093": {"__data__": {"id_": "92898709-fb7a-4d25-8019-b145fab5a093", "embedding": null, "metadata": {"page_label": "4", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1ea323fb-d256-453a-8c8c-2bfd9ef7ef07", "node_type": "4", "metadata": {"page_label": "4", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "hash": "bc0c2a96011f81b587976f14386c2988e38ee037595eaaec2e64ad89d6ee418d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3de1a0f7-bb8e-4a41-bdc2-27645f192a17", "node_type": "1", "metadata": {}, "hash": "6d186b053cee367d76ad49850e061824f2feea989ce165f737be39575dcd64d2", "class_name": "RelatedNodeInfo"}}, "text": "aut ogenstudio.web.appREST  + Sock et endpoints \nfor UI\nP ython  APIaut ogenstudio.worflowmanagerHy dr ate workflow \nspecifications int o A ut oGen \nagents and run tasks\nCommand Lineaut ogenstudio.cliCLI Utilities  \u2028\n \u2028\u2028W eb API\naut ogenstudio ui --por t 8081aut ogenstudio ser v e  --\nworkflow=workflow .jsonBack end APIF r ontend W eb UI APIAB\nAut oGen S tudioP l a y g r o u n dB u i l dG a l l e r y\nF e e d b a c kD o c u m e n t\nG u e s t  u s e rC l o s e  s i d e b a r\nR ecent sessions\nBook generation\nWhat would you like to do?0/2000\nThe children's PDF book titled \"W eather in Seattle\" has been \nsuccessfully created with descriptions and images for each weather \ncondition. The book should now be available as \n\"Seattle_W eather_Childrens_Book.pdf\" on your system.\nY ou can open and view the PDF to ensure that it meets your \nexpectations and contains all the pages with the appropriate images \nand descriptions.\nIf everything looks good, that completes our task. If you need any \nfurther assistance or modifications, please let me know.Agents have completed the task\nR esults (7  f iles )\nSeattle_ W eather_ Childr ens_Book.pdfM essageCostAgent messagesP r ofiler\nGroupchat manager129120 . 152Userproxy29120 . 022Quality Assurance 6030 . 009Content 108120 . 122Image Generator 9010 . 012T ok ensA gentUSD\n10155200 T otal messagesUserproxyGroupchat managerContentImage GeneratorQuality Assurance\nSuccessF ailureUserproxyGroupchat managerContentImage GeneratorQuality AssuranceT ool call\n0 0.511.52\nO bser v e Agents\ncreate a childrens pdf book with 4  pages, each describing the weather \nin seattle. E ach page should have extensive descripitions with images of \nthe weather. Create the images first, then create the text, then the pdf.\nO bserve this responseFigure 2: AUTOGENSTUDIO provides a backend api (web, python, cli) and a UI which implements a playground\n(shown), build andgallery view. In the playground view, users can run tasks in a session based on a workflow. Users\ncan also observe actions taken by agents, reviewing agent messages and metrics based on a profiler module.\ntotal number of messages exchanged, costs (gener-\native AI model tokens consumed and dollar costs),\nhow often agents use tools and the status of tool\nuse (success or failure), for each agent.\n4.1.3 Deploying Workflows\nAUTOGENSTUDIO enables users to export work-\nflows as a JSON configuration file. An exported\nworkflow can be seamlessly integrated into any\nPython application (listing 2), executed as an API\nendpoint using the AUTOGENSTUDIO command\nline interface (figure 2a), or wrapped in a Docker\ncontainer for large-scale deployment on various\nplatforms (Azure, GCP, Amazon, etc.).\nfrom autogenstudio import\nWorkflowManager\nwm = WorkflowManager (\" workflow .\njson \")\nwm. run ( message =\" What is the\nheight of the Eiffel Tower \")\nlisting 2: Workflows can be imported in python apps.\n4.1.4 Template Gallery\nThe UI also features a gallery view - a repository\nof components (skills, models, agents, workflows)that users can import, extend, and reuse in their own\nworkflows. Since each component specification is\ndeclarative (JSON), users can also easily export,\nversion and reshare them.\n4.2 Backend API - Web, Python, and\nCommand Line\nThe backend API comprises three main compo-\nnents: a web API, a Python API, and a command-\nline interface. The web API consists of REST\nendpoints built using the FastAPI library2, sup-\nporting HTTP GET, POST, and DELETE methods.\nThese endpoints interact with several key classes:\nADBManager performs CRUD (Create, Read,\nUpdate, Delete) operations on various entities such\nas skills, models, agents, memory, workflows, and\nsessions. The WorkflowManager class handles\nthe ingestion of declarative agent workflows, con-\nverts them into AUTOGENagent objects, and exe-\ncutes tasks (see listing 2). A Profiler class parses\nagent messages to compute metrics.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3887, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3de1a0f7-bb8e-4a41-bdc2-27645f192a17": {"__data__": {"id_": "3de1a0f7-bb8e-4a41-bdc2-27645f192a17", "embedding": null, "metadata": {"page_label": "4", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1ea323fb-d256-453a-8c8c-2bfd9ef7ef07", "node_type": "4", "metadata": {"page_label": "4", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "hash": "bc0c2a96011f81b587976f14386c2988e38ee037595eaaec2e64ad89d6ee418d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "92898709-fb7a-4d25-8019-b145fab5a093", "node_type": "1", "metadata": {"page_label": "4", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "hash": "bbd368b3f24c469850bd5ca9d75fe2138db94d04e969c1893beaa30b32650675", "class_name": "RelatedNodeInfo"}}, "text": "Since each component specification is\ndeclarative (JSON), users can also easily export,\nversion and reshare them.\n4.2 Backend API - Web, Python, and\nCommand Line\nThe backend API comprises three main compo-\nnents: a web API, a Python API, and a command-\nline interface. The web API consists of REST\nendpoints built using the FastAPI library2, sup-\nporting HTTP GET, POST, and DELETE methods.\nThese endpoints interact with several key classes:\nADBManager performs CRUD (Create, Read,\nUpdate, Delete) operations on various entities such\nas skills, models, agents, memory, workflows, and\nsessions. The WorkflowManager class handles\nthe ingestion of declarative agent workflows, con-\nverts them into AUTOGENagent objects, and exe-\ncutes tasks (see listing 2). A Profiler class parses\nagent messages to compute metrics. When a user\ninitiates a task within a session, the system retrieves\nthe session history, instantiates agents based on\ntheir serialized representations from the database,\nexecutes the task, streams intermediate messages to\nthe UI via websocket, and returns the final results.\nAUTOGENSTUDIO also provides a command-line\n2FastAPI: https://fastapi.tiangolo.com/", "mimetype": "text/plain", "start_char_idx": 3074, "end_char_idx": 4245, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bf84070f-da7b-405b-b045-711b7a3afc1c": {"__data__": {"id_": "bf84070f-da7b-405b-b045-711b7a3afc1c", "embedding": null, "metadata": {"page_label": "5", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2ebc0465-d661-43c9-80a1-c6df4100cd2f", "node_type": "4", "metadata": {"page_label": "5", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "hash": "b5c02356c24bcc118331dcd66983973b9a7c9b9561b26c44e5695ace78a417fd", "class_name": "RelatedNodeInfo"}}, "text": "interface with utilities for launching the bundled UI\nand running exported workflows as API endpoints.\n5 Usage and Evaluation\nIn this project, we have adopted an in-situ, iterative\nevaluation approach. Since its release on GitHub\n(5 months), the AUTOGENSTUDIO package has\nbeen installed over 200 Ktimes and has been itera-\ntively improved based on feedback from usage (>\n135GitHub issues). Issues highlighted several user\npain points that were subsequently addressed in-\ncluding: (a) challenges in defining, persisting, and\nreusing components, resolved by implementing a\ndatabase layer; (b) difficulties in authoring compo-\nnents, resolved by supporting automated tool gener-\nation from descriptions and integrating an IDE for\nediting tools; (c) frustrations caused by components\nfailing during end-to-end tests, addressed by incor-\nporating a test button for components (e.g.,models)\nand workflows in the build view. Figure 3 displays\na plot of all AUTOGENSTUDIO issues. Each point\nrepresents an issue, based on an embedding of its\ntext (title + body) using OpenAI\u2019s text-embedding-\n3-large model. The embeddings were reduced to\ntwo dimensions using UMAP, clustered with K-\nMeans ( k= 8), and cluster labels generated using\nGPT-4 (grounded on 10 samples from its centroid).\nFinally, in Appendix A, we demonstrate how AU-\nTOGENSTUDIO can effectively be used to support\nan engineer persona in rapidly prototyping, testing,\nand iteratively debugging a MULTI -AGENT work-\nflow, and deploying it as an API endpoint to address\na concrete task (generating books).\n6 Emerging Design Patterns and\nResearch Directions\nIn the following section, we outline some of the\nhigh-level emerging patterns which we hope can\nhelp inform the design of no-code interfaces for\nbuilding next-generation multi-agent applications.\n6.1 Define-and-Compose Workflows\nAllow users to author workflows by\ndefining components and composing\nthem (via drag-and-drop actions) into\nmulti-agent workflows.\nA multi-agent system can have a wide array of\nparameters to configure. We have found that select-\ning the right visual presentation of the workflow to\nAutoGen Studio Feature\nRequests: Workflow\nSharing, File Uploads, UI\nImprovements, and Model\nTesting (14)Issues with Autogen\nStudio: Skills not\nupdating, Code execution,\nand Group Chat (21)Issues with API Keys,\nModel Configuration, and\nLocal Server Connections\n(27)\nIssues with Group Chat\nWorkflow, Agent Creation,\nand Model Changes (18)AutoGen Studio 2\nCompatibility, API\nIssues, and Documentation\nUpdates (10)Issues with AutoGen\nStudio: Docker access,\nvalidation errors, and\ncompatibility (17)\nAutoGen Studio: Database\nImplementation, Custom\nConfigurations, and\nPerformance Enhancements\n(14)Accessibility and\nMultimodality in Autogen\nStudio, UI Improvements,\nGroup Chat Support, and\nTest Suite (14)AutoGen Studio GitHub Issue Visualization (UMAP)Figure 3: Plot of GitHub issues ( n= 8clusters) from\ntheAUTOGENSTUDIO repo. User feedback ranged\nfrom support with workflow authoring tools (e.g., the\nability configure and test models) to general installation.\nhelping users understand what parameters to config-\nure (discovery), and how to configure them. Specif-\nically, we have found that a define-and-compose\nworkflow, where entities are first defined and per-\nsisted independently, and then composed ultimately\ninto multi-agent workflows, provides a good de-\nveloper experience. This includes providing tools\nto support authoring entities e.g., the ability de-\nfine and test models, an IDE for generating/editing\ntools (code), and a a canvas-based visual layout\nof workflows with drag-and-drop interaction for\nassociating entities in the workflow.\n6.2 Debugging and Sensemaking Tools\nProvide robust tools to help users debug,\ninterpret, and rationalize the behavior and\noutputs of multi-agent systems.\nMulti-agent workflows can be brittle and fail for\nmultiple reasons, ranging from improperly config-\nured models to poor instructions for agents, im-\nproper tool configuration for agents or termination\nconditions. A critical request has been for tools\nto help users debug and make sense of agent re-\nsponses.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4130, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bcc175c8-b731-440c-9737-de8224a15aa4": {"__data__": {"id_": "bcc175c8-b731-440c-9737-de8224a15aa4", "embedding": null, "metadata": {"page_label": "6", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ec7b4db9-f8b8-4cab-8d5c-396c48a2738f", "node_type": "4", "metadata": {"page_label": "6", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "hash": "b6541810263eb7245450259506b42f55be220eac21845f0fd2126293731f320a", "class_name": "RelatedNodeInfo"}}, "text": "6.3 Export and Deployment\nEnable seamless export and deployment\nof multi-agent workflows to various plat-\nforms and environments.\nWhile a no-code tool like AUTOGENSTUDIO\nenables rapid iteration and demonstration of work-\nflows, the natural progression for most use cases\nis that developers want to replicate the same out-\ncomes but integrated as parts of their core appli-\ncations. This stage requires seamless export and\ndeployment of multi-agent workflows to various\nplatforms and environments.\n6.4 Collaboration and Sharing\nFacilitate user collaboration on multi-\nagent workflow development and allow\neasy sharing of creations within the com-\nmunity.\nCollaboration and sharing are key to accelerat-\ning innovation and improving multi-agent systems.\nBy enabling users to collaborate on workflow de-\nvelopment, share their creations, and build upon\neach other\u2019s work, a more dynamic and innova-\ntive development environment can be cultivated.\nTools and features that support real-time collab-\noration, version control, and seamless sharing of\nworkflows and components are essential to foster\na community-driven approach. Additionally, offer-\ning a repository or gallery where users can publish\nand share their workflows, skills, and agents pro-\nmotes communal learning and innovation.\n7 Future Research Directions\nWhile we have explored early implementations\nof the design requirements mentioned above, our\nefforts in building AUTOGENSTUDIO have also\nidentified two important future research areas and\nassociated research questions.\n\u2022Offline Evaluation Tools : This encompasses\nquestions such as how can we measure the per-\nformance, reliability, and reusability of agents\nacross tasks? How can we better understand\ntheir strengths and limitations? How can we ex-\nplore alternative scenarios and outcomes? And\nhow can we compare different agent architec-\ntures and collaboration protocols?\u2022Understanding and quantifying the impact\nof multi-agent system design decisions : These\nquestions include determining the optimal num-\nber and composition of agents for a given prob-\nlem, the best way to distribute responsibilities\nand coordinate actions among agents, and the\ntrade-offs between centralized and decentralized\ncontrol or between homogeneous and heteroge-\nneous agents.\n\u2022Optimizing of multi-agent systems : Research\ndirections here include the dynamic generation\nof agents based on task requirements and avail-\nable resources, tuning workflow configurations\nto achieve the best performance, and adapting\nagent teams to changing environments and user\npreferences. Furthermore, how can we leverage\nhuman oversight and feedback to improve agent\nreliability, task performance and safety?\n8 Conclusion\nThis paper introduced AUTOGENSTUDIO , a no-\ncode developer tool for rapidly prototyping, debug-\nging, and evaluating multi-agent workflows. Key\nfeatures include a drag-and-drop interface for agent\nworkflow composition, interactive debugging capa-\nbilities, and a gallery of reusable agent components.\nThrough widespread adoption, we identified emerg-\ning design patterns for multi-agent developer tool-\ning - a define and compose approach to authoring\nworkflows, debugging tools to make sense of agent\nbehaviors, tools to enable deployment and collabo-\nrative sharing features. AUTOGENSTUDIO lowers\nthe barrier to entry for multi-agent application de-\nvelopment, potentially accelerating innovation in\nthe field. Finally we outline future research direc-\ntions including developing offline evaluation tools,\nablation studies to quantify the impact of MULTI -\nAGENT systems design decisions and methods for\noptimizing multi-agent systems.\n9 Ethics Statement\nAUTOGENSTUDIO is designed to provide a no-\ncode environment for rapidly prototyping and test-\ning multi-agent workflows. Our goal is to responsi-\nbly advance research and practice in solving prob-\nlems with multiple agents and to develop tools that\ncontribute to human well-being. Along with AU-\nTOGEN,AUTOGENSTUDIO is committed to im-\nplementing features that promote safe and reliable\noutcomes. For example, AUTOGENSTUDIO of-\nfers profiling tools to make sense of agent actions", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4139, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2244e4b0-72f3-4cd2-bbfc-f52a08a52783": {"__data__": {"id_": "2244e4b0-72f3-4cd2-bbfc-f52a08a52783", "embedding": null, "metadata": {"page_label": "7", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "13bb916b-9ea6-4b23-a10b-fbeecd0e544b", "node_type": "4", "metadata": {"page_label": "7", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "hash": "e546f75588ab2a6ace3f153422c79afa96798e77575dc39ebfdafd87d805677d", "class_name": "RelatedNodeInfo"}}, "text": "and safeguards, such as support for Docker envi-\nronments for code execution. This feature helps\nensure that agents operate within controlled and se-\ncure environments, reducing the risk of unintended\nor harmful actions. For more information on our\napproach to responsible AI in AutoGen, please re-\nfer to transparency FAQS here. Finally, AUTOGEN\nSTUDIO is not production ready i.e., it does not\nfocus on implementing authentication and other\nsecurity measures that are required for production\nready deployments.\nAcknowledgements\nWe would like to thank members of the open-source\nsoftware (OSS) community and the AI Frontiers\norganization at Microsoft Research for discussions\nand feedback along the way. Specifically, we would\nlike to thank Piali Choudhury, Ahmed Awadallah,\nRobin Moeur, Jack Gerrits, Robert Barber, Grace\nProebsting, Michel Pahud, Qingyun Wu, Harsha\nNori and others for feedback and comments.\nReferences\nHarrison Chase. 2022. LangChain. Github .\nVictor Dibia. 2023. Lida: A tool for automatic gener-\nation of grammar-agnostic visualizations and info-\ngraphics using large language models. arXiv preprint\narXiv:2303.02927 .\nYilun Du, Shuang Li, Antonio Torralba, Joshua B Tenen-\nbaum, and Igor Mordatch. 2023. Improving factual-\nity and reasoning in language models through multia-\ngent debate. arXiv preprint arXiv:2305.14325 .\nGuohao Li, Hasan Hammoud, Hani Itani, Dmitrii\nKhizbullin, and Bernard Ghanem. 2024. Camel:\nCommunicative agents for\" mind\" exploration of\nlarge language model society. Advances in Neural\nInformation Processing Systems , 36.\nTian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang,\nYan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, and\nShuming Shi. 2023. Encouraging divergent thinking\nin large language models through multi-agent debate.\narXiv preprint arXiv:2305.19118 .\nNelson F Liu, Kevin Lin, John Hewitt, Ashwin Paran-\njape, Michele Bevilacqua, Fabio Petroni, and Percy\nLiang. 2024. Lost in the middle: How language mod-\nels use long contexts. Transactions of the Association\nfor Computational Linguistics , 12:157\u2013173.\nGr\u00e9goire Mialon, Roberto Dess\u00ec, Maria Lomeli, Christo-\nforos Nalmpantis, Ram Pasunuru, Roberta Raileanu,\nBaptiste Rozi\u00e8re, Timo Schick, Jane Dwivedi-Yu,\nAsli Celikyilmaz, et al. 2023. Augmented language\nmodels: a survey. arXiv preprint arXiv:2302.07842 .Bo Qiao, Liqun Li, Xu Zhang, Shilin He, Yu Kang,\nChaoyun Zhang, Fangkai Yang, Hang Dong, Jue\nZhang, Lu Wang, et al. 2023. Taskweaver:\nA code-first agent framework. arXiv preprint\narXiv:2311.17541 .\nQingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu,\nBeibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang,\nShaokun Zhang, Jiale Liu, Ahmed Hassan Awadal-\nlah, Ryen W White, Doug Burger, and Chi Wang.\n2023. Autogen: Enabling next-gen llm applications\nvia multi-agent conversation framework. arxiv .\nZhiyong Wu, Chengcheng Han, Zichen Ding, Zhenmin\nWeng, Zhoumianze Liu, Shunyu Yao, Tao Yu, and\nLingpeng Kong. 2024. Os-copilot: Towards gener-\nalist computer agents with self-improvement. arXiv\npreprint arXiv:2402.07456 .\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak\nShafran, Karthik Narasimhan, and Yuan Cao. 2022.\nReact: Synergizing reasoning and acting in language\nmodels. arXiv preprint arXiv:2210.03629 .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3212, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "76358c52-9704-4d91-90b3-c3e7725d48b8": {"__data__": {"id_": "76358c52-9704-4d91-90b3-c3e7725d48b8", "embedding": null, "metadata": {"page_label": "8", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b5fa37a6-cd7c-4113-9e2c-2cdf8c86f8c6", "node_type": "4", "metadata": {"page_label": "8", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}, "hash": "82196704fd7b2ff9409cf28772d863f90353ae596a9da8d08a79000908572791", "class_name": "RelatedNodeInfo"}}, "text": "A Jack the Software Engineer Persona\nUse Case\nJack is a junior software engineer who has recently\njoined SoftwareCon. As part of his tasks, he is\nrequired to create an application that can generate a\nvariety of short books. The initial version should fo-\ncus on generating children\u2019s books (age 5 -8 years\nold) based on a given query (e.g., create a book for\nkids on how the sun works ) with the expectation\nof being generalized to support other generic tasks.\nJack has heard about a MULTI -AGENT approach to\nbuilding systems that can address a variety of tasks\nthrough autonomous collaboration between agents.\nTo explore this approach, he begins by perusing\ntheAUTOGENSTUDIO documentation, installs it,\nlaunches the UI, and performs the following steps:\nA.1 Step 1: Define and Compose a Workflow\nJack starts with the Build view, where he reviews\nthe default skills that come with AUTOGENSTU-\nDIO. He sees that there are two relevant skills\ngenerate _pd fs andgenerate _images . He veri-\nfies that he has the appropriate API keys for the\ngenerate _image skill. Next, he creates a GPT3.5\nmodel and adds an API key.\nFollowing best practices, Jack knows that the\nbasic agent team with AUTOGENconsists of a\nUserProxyAgent that can execute code and an As-\nsistantAgent that can solve tasks as well as write\ncode or call available tools/skills. He creates both\nof these agents; for his AssistantAgent , he ensures\nthat he attaches the GPT4 model he created previ-\nously and also attaches both skills. Jack moves on\nto the workflow tab and creates a new autonomous\nchat workflow where he specifies the UserProxyA-\ngent as the initiator and his AssistantAgent as the\nreceiver.\nA.2 Step 2: Test and Iterate\nWithin the workflow tab, Jack tests the workflow\nimmediately and quickly observes a few issues. Us-\ning the profiler tool and visualization of messages\nexchanged by the agents, he notices that there seem\nto be quality issues with the content of the book -\nnamely, the AssistantAgent seems to generate very\nshort messages and hence the book pages contains\nonly 2 sentences per page whereas the requirements\nstate that the kids are slightly older and can read\nmuch longer text.\nTo remedy these issues, Jack takes two actions.\nFirst, he attempts to extend the base instructionsof his AssistantAgent , but still doesn\u2019t get pages\nwith more than 3 sentences across interactive tests.\nHe recalls that using more agents can help sep-\narate focus and improve task performance. He\nthen switches to creating 4 agents: a UserProxy ,\naContentAssistant with detailed instructions on\ngenerating the content for each page, a QualityAs-\nsuranceAssistant to verify the pages meet parame-\nters, and an ImageGeneratorAssistant focused on\ngenerating images for the book. He then creates a\nGroupChat agent and adds his list of agents to it.\nNext, he creates a new workflow where the receiver\nis the GroupChat agent and tests the application\nacross a few tries. Jack is satisfied with the results\nas full-page stories are now generated correctly.\nIn addition, Jack is concerned about costs but can\neasily use the observe message button to explore\nduration, tokens used by agents, tool/skill use and\nLLM dollar costs for each task run.\nA.3 Step 3: Export and Share\nAt this point, Jack has two final tasks: he wants to\nshare his work with colleagues for feedback and\nthen provide an API they can prototype with. AU-\nTOGENSTUDIO makes sharing easy; First, Jack\ncan simply export and share a link to successful ses-\nsions. Second, he can also download his workflow\nand share it with colleagues, saving it in a version\ncontrol system like Git. Third, he can spin up an\nAPI endpoint where the agents can respond to task\nrequests using cli commands \u2018autogenstudio serve\n\u2013port 8000\u2018. He can also spin up a docker container\nusing the AUTOGENSTUDIO serve command and\nscale it on any platform of his choice (Azure, AWS,\nGCP, Hugging Face).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3904, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"d73b33d0-b3b2-4b38-b850-64cd7e05c342": {"node_ids": ["2fbd7d4e-bed3-400f-b11c-83e1655c8690"], "metadata": {"page_label": "1", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}}, "302b4cd0-5ce1-468b-9e5e-00b5dec5b011": {"node_ids": ["335fc737-6548-4460-bef4-024cd5e0fa43"], "metadata": {"page_label": "2", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}}, "909d2f5b-7e17-4657-95af-97b264873214": {"node_ids": ["45d0ada2-5336-4379-9bd3-061fdfb48be5"], "metadata": {"page_label": "3", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}}, "1ea323fb-d256-453a-8c8c-2bfd9ef7ef07": {"node_ids": ["92898709-fb7a-4d25-8019-b145fab5a093", "3de1a0f7-bb8e-4a41-bdc2-27645f192a17"], "metadata": {"page_label": "4", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}}, "2ebc0465-d661-43c9-80a1-c6df4100cd2f": {"node_ids": ["bf84070f-da7b-405b-b045-711b7a3afc1c"], "metadata": {"page_label": "5", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}}, "ec7b4db9-f8b8-4cab-8d5c-396c48a2738f": {"node_ids": ["bcc175c8-b731-440c-9737-de8224a15aa4"], "metadata": {"page_label": "6", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}}, "13bb916b-9ea6-4b23-a10b-fbeecd0e544b": {"node_ids": ["2244e4b0-72f3-4cd2-bbfc-f52a08a52783"], "metadata": {"page_label": "7", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}}, "b5fa37a6-cd7c-4113-9e2c-2cdf8c86f8c6": {"node_ids": ["76358c52-9704-4d91-90b3-c3e7725d48b8"], "metadata": {"page_label": "8", "file_name": "ag-studio.pdf", "file_path": "/Users/tylerreed/llamaindex/pdf/ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-08", "last_modified_date": "2024-09-08"}}}}